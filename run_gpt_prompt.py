import json
import math
import re
import sys

from LLM.moda_agent import ModaAgent

sys.path.append('../')

moda = ModaAgent()
can_go_place = ['åŒ»é™¢', 'å’–å•¡åº—', 'èœœé›ªå†°åŸ', 'å­¦æ ¡', 'å°èŠ³å®¶', 'ç«é”…åº—', 'ç»¿é“', 'å°æ˜å®¶', 'å°ç‹å®¶', 'è‚¯å¾·åŸº',
                    'ä¹¡æ‘åŸº', 'å¥èº«æˆ¿', 'ç”µå½±é™¢', 'å•†åœº', 'æµ·è¾¹']


# æ¯æ—¥è®¡åˆ’è¡¨
def run_gpt_prompt_generate_hourly_schedule(persona,now_time):

    def __func_clean_up(gpt_response):

        cr = gpt_response
        return cr

    def __func_validate(gpt_response):
        try:
            gpt_response = gpt_response.replace("```","").split("json")[1][1:]
            gpt_response = json.loads(gpt_response.strip('\n'))['output']
            total_time = sum(item[1] for item in gpt_response)
            print("total_time",total_time)
            if total_time > 2000:
                return False
            __func_clean_up(gpt_response)
        except:
            return False
        return True



    generate_prompt = ModaAgent.generate_prompt(
        [persona,now_time],
        r"./LLM/prompt_template/ç”Ÿæˆæ—¥ç¨‹å®‰æ’æ—¶é—´è¡¨.txt")
    output = moda.ollama_safe_generate_response(generate_prompt,
                                                "",
                                                "ä½ æ²¡å¿…è¦è€ƒè™‘æˆ‘ç»™çš„ä¾‹å­çš„æ—¶é—´ï¼Œè¯·å¸®æˆ‘åˆç†å®‰æ’ï¼Œä¸¥æ ¼éµå®ˆ['æ—¶é—´']ä¹‹å’Œä¸èƒ½è¶…è¿‡1920ï¼Œä½ ä¸éœ€è¦è°ƒæ•´ï¼Œåªéœ€è¦ç»™æˆ‘è¾“å‡ºä¸€ä¸ªæœ€ç»ˆçš„ç»“æœï¼Œæˆ‘éœ€è¦ä¸€ä¸ªæ ‡å‡†çš„æ•°ç»„æ ¼å¼,",
                                                10,
                                                __func_validate,
                                                __func_clean_up)
    # print(output)
    if "json" in output:
        output = output.replace("```", "").split("json")[1][1:]
        output = json.loads(output.strip('\n'))['output']
        return output

    else:
        # print(output)
        return output


# æ¯å¤©è‹é†’æ—¶é—´
def run_gpt_prompt_wake_up_hour(persona,now_time,hourly_schedule):
    def __func_clean_up(gpt_response, prompt=""):
        cr = gpt_response
        return cr

    def __func_validate(gpt_response, prompt=""):
        try:
            if "output" in gpt_response:
                pattern = r'"output"\s*:\s*"([^"]+)"'
                match = re.search(pattern, gpt_response)
                output_value = match.group(1)
                __func_clean_up(output_value, prompt="")
            else:
                return False
        except:
            return False
        return True
    generate_prompt = ModaAgent.generate_prompt(
        [persona,now_time,hourly_schedule],
        r"./LLM/prompt_template/èµ·åºŠæ—¶é—´.txt")
    output = moda.ollama_safe_generate_response(generate_prompt, "",
                                                        "åªéœ€è¦ç»™æˆ‘è¾“å‡ºä¸€ä¸ªæœ€ç»ˆçš„ç»“æœä¸éœ€è¦ç»™æˆ‘å…¶ä»–ä»»ä½•ä¿¡æ¯ï¼Œæˆ‘éœ€è¦ä¸€ä¸ªæ ‡å‡†çš„æ—¥æœŸæ ¼å¼ï¼Œæ¯”å¦‚ï¼š07-01ï¼ˆè¡¨ç¤ºæ—©ä¸Šä¸ƒç‚¹é›¶ä¸€åˆ†èµ·åºŠï¼‰",
                                                        5,
                                                        __func_validate, __func_clean_up)
    # print(output)
    pattern = r'"output"\s*:\s*"([^"]+)"'
    match = re.search(pattern, output)
    output = match.group(1)
    return output

# è¡ŒåŠ¨è½¬è¡¨æƒ…
def run_gpt_prompt_pronunciatio(Action_dec):
    def __chat_func_clean_up(gpt_response):  ############
        cr = gpt_response.strip()
        if len(cr) > 3:
            cr = cr[:3]
        return cr
    def __chat_func_validate(gpt_response):  ############
        try:
            gpt_response = json.loads(gpt_response)["output"]
            __chat_func_clean_up(gpt_response)
        except:
            return False
        return True
    example_output = "ğŸ›ğŸ§–â€â™€ï¸"  ########
    special_instruction = "è¾“å‡ºåªåŒ…å«è¡¨æƒ…ç¬¦å·"  ########
    generate_prompt = ModaAgent.generate_prompt(
        [Action_dec],
        r"./LLM/prompt_template/è¡Œä¸ºè½¬ä¸ºå›¾æ ‡æ˜¾ç¤º.txt")
    output = moda.ollama_safe_generate_response(generate_prompt, example_output, special_instruction, 7,__chat_func_validate,__chat_func_clean_up,'{"output":"ğŸ§˜ï¸"}')
    return json.loads(output)['output']


# ä¸¤ä¸ªæ™ºèƒ½ä½“é—´çš„å¯¹è¯-test
def double_agents_chat(maze,agent1_name,agent2_name,curr_context,init_summ_idea,target_summ_idea):
    def __chat_func_clean_up(gpt_response):  ############
        return gpt_response

    def __chat_func_validate(gpt_response):  ############
        try:
            __chat_func_clean_up(gpt_response)
        except:
            return False
        return True

    generate_prompt = ModaAgent.generate_prompt(
        [maze,agent1_name, agent2_name, curr_context, init_summ_idea, target_summ_idea], r"./LLM\prompt_template/èŠå¤©.txt")

    example_output = '[["ä¸¹å°¼", "ä½ å¥½"], ["è‹å…‹", "ä½ ä¹Ÿæ˜¯"] ... ]'
    special_instruction = 'è¾“å‡ºåº”è¯¥æ˜¯ä¸€ä¸ªåˆ—è¡¨ç±»å‹ï¼Œå…¶ä¸­å†…éƒ¨åˆ—è¡¨çš„å½¢å¼ä¸º[â€œ<åå­—>â€ï¼Œâ€œ<è¯è¯­>â€]ã€‚'

    x = moda.ollama_safe_generate_response(generate_prompt, example_output, special_instruction, 3,__chat_func_validate,__chat_func_clean_up)

    return json.loads(x)['output']


# åˆ¤æ–­åšè¿™ä»¶äº‹æƒ…éœ€è¦å»å“ªä¸ªåœ°æ–¹
def go_map(agent_name, home , curr_place, can_go, curr_task):
    def __chat_func_clean_up(gpt_response):  ############
        return gpt_response

    def __chat_func_validate(gpt_response):  ############
        try:
            if "output" in gpt_response:
                pattern = r'"output"\s*:\s*"([^"]+)"'
                match = re.search(pattern, gpt_response)
                output_value = match.group(1)
                __chat_func_clean_up(output_value)
            else:
                return False
        except:
            return False
        return True

    example_output = 'æµ·è¾¹'
    special_instruction = ''

    generate_prompt = ModaAgent.generate_prompt(
        [agent_name,home , curr_place, can_go, curr_task],
        r"./LLM/prompt_template/è¡ŒåŠ¨éœ€è¦å»çš„åœ°æ–¹.txt")

    output = moda.ollama_safe_generate_response(generate_prompt, example_output, special_instruction, 3,__chat_func_validate,__chat_func_clean_up)
    # print(output,"map")
    pattern = r'"output"\s*:\s*"([^"]+)"'
    match = re.search(pattern, output)
    output = match.group(1)
    return output

# æ€»ç»“ä»Šå¤©çš„ä¸€åˆ‡å†™å…¥è®°å¿†æ–‡ä»¶
def tess():
    pass

if __name__ == '__main__':
    class agent_v:
        def __init__(self, name, MAP):
            self.name = name
            self.MAP = MAP
            self.schedule = []
            self.Visual_Range = 1
            self.home = ""
            self.curr_place = ""
            self.position = (0, 0)
            self.schedule_time = []
            self.last_action = ""
            self.memory = ""
            self.wake = ""
            self.curr_action = ""
            self.curr_action_pronunciatio = ""
            self.ziliao = open(f"./agents/{self.name}/1.txt", encoding="utf-8").readlines()

        def getpositon(self):
            return self.position

        def goto_scene(self, scene_name):
            for row_index, row in enumerate(self.MAP):
                for col_index, cell in enumerate(row):
                    if cell == scene_name:
                        self.position = (row_index, col_index)
                        self.curr_place = scene_name
            return None  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å› None

        def Is_nearby(self, position):
            x1 = self.position[0]
            x2 = position[0]
            y1 = self.position[1]
            y2 = position[1]
            manhattan_distance = abs(x1 - x2) + abs(y1 - y2)
            # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
            euclidean_distance = math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)
            # åˆ¤æ–­æ˜¯å¦ç›¸é‚»
            return manhattan_distance == 1 or euclidean_distance == 1 or euclidean_distance == math.sqrt(2)


    MAP = [['åŒ»é™¢', 'å’–å•¡åº—', '#', 'èœœé›ªå†°åŸ', 'å­¦æ ¡', '#', '#', 'å°èŠ³å®¶', '#', '#', 'ç«é”…åº—', '#', '#'],
           ['#', '#', 'ç»¿é“', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#'],
           ['#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#'],
           ['#', '#', '#', '#', '#', '#', 'å°æ˜å®¶', '#', 'å°ç‹å®¶', '#', '#', '#', '#'],
           ['#', '#', 'è‚¯å¾·åŸº', 'ä¹¡æ‘åŸº', '#', '#', '#', '#', '#', '#', '#', 'å¥èº«æˆ¿', '#'],
           ['ç”µå½±é™¢', '#', '#', '#', '#', 'å•†åœº', '#', '#', '#', '#', '#', '#', '#'],
           ['#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#'],
           ['#', '#', '#', '#', '#', '#', '#', 'æµ·è¾¹', '#', '#', '#', '#', '#']]
    agent1 = agent_v("å°æ˜", MAP)
    can_go_place = ['åŒ»é™¢', 'å’–å•¡åº—', 'èœœé›ªå†°åŸ', 'å­¦æ ¡', 'å°èŠ³å®¶', 'ç«é”…åº—', 'ç»¿é“', 'å°æ˜å®¶', 'å°ç‹å®¶', 'è‚¯å¾·åŸº',
                    'ä¹¡æ‘åŸº', 'å¥èº«æˆ¿', 'ç”µå½±é™¢', 'å•†åœº', 'æµ·è¾¹']
    x = run_gpt_prompt_generate_hourly_schedule(agent1.ziliao[6],'2024-11-19')
    # print(x)
    # print(type(x))
